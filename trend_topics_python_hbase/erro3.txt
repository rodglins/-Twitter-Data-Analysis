21/09/21 21:19:27 INFO org.sparkproject.jetty.util.log: Logging initialized @3326ms to org.sparkproject.jetty.util.log.Slf4jLog
21/09/21 21:19:27 INFO org.sparkproject.jetty.server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_292-b10
21/09/21 21:19:27 INFO org.sparkproject.jetty.server.Server: Started @3454ms
21/09/21 21:19:27 INFO org.sparkproject.jetty.server.AbstractConnector: Started ServerConnector@6659a72f{HTTP/1.1, (http/1.1)}{0.0.0.0:39895}
21/09/21 21:19:27 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at cluster-rodglins-m/10.128.0.6:8032
21/09/21 21:19:28 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at cluster-rodglins-m/10.128.0.6:10200
21/09/21 21:19:28 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found
21/09/21 21:19:28 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.
21/09/21 21:19:29 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1632172312677_0006
21/09/21 21:19:30 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at cluster-rodglins-m/10.128.0.6:8030
21/09/21 21:19:32 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.
21/09/21 21:19:33 INFO org.apache.hadoop.mapred.FileInputFormat: Total input files to process : 39
Traceback (most recent call last):
  File "/tmp/job-4f402f1f/trend_analysis_spark.py", line 25, in <module>
    add=tweet.reduceByKey(lambda x,y:x+y)
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1891, in reduceByKey
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2136, in combineByKey
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2581, in _defaultReducePartitions
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2935, in getNumPartitions
  File "/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1304, in __call__
  File "/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o49.partitions.
: java.io.IOException: Path: /lost+found is a directory, which is not supported by the record reader when `mapreduce.input.fileinputformat.input.dir.recursive` is false.
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:238)
	at org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:300)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:296)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:300)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:296)
	at org.apache.spark.api.java.JavaRDDLike.partitions(JavaRDDLike.scala:61)
	at org.apache.spark.api.java.JavaRDDLike.partitions$(JavaRDDLike.scala:61)
	at org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

21/09/21 21:19:33 INFO org.sparkproject.jetty.server.AbstractConnector: Stopped Spark@6659a72f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
21/09/21 21:19:33 WARN org.apache.spark.network.server.TransportChannelHandler: Exception in connection from /10.128.0.7:39366
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
